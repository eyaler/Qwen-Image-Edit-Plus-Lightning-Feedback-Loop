{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMz4/heIbYgvlPWvEVbiMHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/Qwen-Image-Edit-Plus-Lightning-Feedback-Loop/blob/main/Qwen_Image_Edit_Plus_Lightning_Feedback_Loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "based on: https://github.com/radames/nano-banana-loop\n",
        "\n",
        "requires: A100 High-RAM\n"
      ],
      "metadata": {
        "id": "1pcCkl2nZ1Rt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y6_cdFzgG8Xo"
      },
      "outputs": [],
      "source": [
        "#@title Install\n",
        "\n",
        "!pip install git+https://github.com/huggingface/diffusers\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from diffusers import FlowMatchEulerDiscreteScheduler, QwenImageEditPlusPipeline\n",
        "from diffusers.models import QwenImageTransformer2DModel\n",
        "from diffusers.utils import load_image\n",
        "from google.colab import files\n",
        "from IPython.display import Video\n",
        "import re\n",
        "from time import perf_counter\n",
        "\n",
        "\n",
        "lora = '8steps'  #@param ['4steps', '8steps', 'None']\n",
        "\n",
        "torch_dtype = torch.bfloat16\n",
        "model_name = 'Qwen/Qwen-Image-Edit-2509'\n",
        "steps = 50\n",
        "cfg = 4\n",
        "negative_prompt = ' '\n",
        "\n",
        "if lora != 'None':\n",
        "  lora_repo = 'lightx2v/Qwen-Image-Lightning'\n",
        "  lora_path = f'Qwen-Image-Edit-2509/Qwen-Image-Edit-2509-Lightning-{lora}-V1.0-bf16.safetensors'\n",
        "  steps = int(re.search('\\\\d+(?=steps)', lora_path).group())\n",
        "  cfg = 1\n",
        "  negative_prompt = None\n",
        "\n",
        "  model = QwenImageTransformer2DModel.from_pretrained(model_name, subfolder='transformer', torch_dtype=torch_dtype)\n",
        "\n",
        "  scheduler_config = {\n",
        "      \"base_image_seq_len\": 256,\n",
        "      \"base_shift\": math.log(3),  # We use shift=3 in distillation\n",
        "      \"invert_sigmas\": False,\n",
        "      \"max_image_seq_len\": 8192,\n",
        "      \"max_shift\": math.log(3),  # We use shift=3 in distillation\n",
        "      \"num_train_timesteps\": 1000,\n",
        "      \"shift\": 1.0,\n",
        "      \"shift_terminal\": None,  # set shift_terminal to None\n",
        "      \"stochastic_sampling\": False,\n",
        "      \"time_shift_type\": \"exponential\",\n",
        "      \"use_beta_sigmas\": False,\n",
        "      \"use_dynamic_shifting\": True,\n",
        "      \"use_exponential_sigmas\": False,\n",
        "      \"use_karras_sigmas\": False,\n",
        "  }\n",
        "  scheduler = FlowMatchEulerDiscreteScheduler.from_config(scheduler_config)\n",
        "  pipe = QwenImageEditPlusPipeline.from_pretrained(model_name, transformer=model, scheduler=scheduler, torch_dtype=torch_dtype)\n",
        "  pipe.load_lora_weights(lora_repo, weight_name=lora_path)\n",
        "else:\n",
        "  pipe = QwenImageEditPlusPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)\n",
        "\n",
        "pipe = pipe.to('cuda')\n",
        "pipe.set_progress_bar_config(disable=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload image\n",
        "\n",
        "uploaded = files.upload('/content/sample_data')\n",
        "if uploaded:\n",
        "  img_filename = list(uploaded)[0]\n",
        "  init_image = load_image(img_filename)\n",
        "  print(img_filename)\n",
        "init_image"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TGGAdG6iRgCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate\n",
        "\n",
        "task_or_prompt = 'next'  #@param [\"next\",\"prev\",\"motion\",\"background\",\"up\",\"down\",\"left\",\"right\",\"rotate-left\",\"rotate-right\",\"zoom-in\",\"zoom-out\",\"future\",\"past\",\"funny\",\"serious\",\"dramatic\",\"peaceful\",\"vintage\",\"futuristic\",\"nature\",\"urban\",\"minimalist\",\"crowded\",\"empty\"] {\"allow-input\":true}\n",
        "#@markdown (you can also write a custom prompt)\n",
        "seed = 42  #@param {type: 'integer'}\n",
        "duration_secs = 5  #@param {type: 'number'}\n",
        "fps = 8  #@param {type: 'integer'}\n",
        "\n",
        "prompts = {\n",
        "    \"next\": \"Show the next scene one second later\",\n",
        "    \"prev\": \"Show the previous scene one second before\",\n",
        "    \"motion\": \"Apply subtle motions to create the next animation frame\",\n",
        "    \"background\": \"Gently change the background of the moving object\",\n",
        "    \"up\": \"Gently pan the camera up, extending the image.\",\n",
        "    \"down\": \"Gently pan the camera down, extending the image.\",\n",
        "    \"left\": \"Gently pan the camera left, extending the image.\",\n",
        "    \"right\": \"Gently pan the camera right, extending the image.\",\n",
        "    \"rotate-left\": \"Gently rotate the camera counter-clockwise, extending the borders to fit the new perspective.\",\n",
        "    \"rotate-right\": \"Gently rotate the camera clockwise, extending the borders to fit the new perspective.\",\n",
        "    \"zoom-in\": \"Gently zoom in on the center of the image, maintaining focus and detail.\",\n",
        "    \"zoom-out\": \"Gently zoom out from the image, revealing more of the surrounding scene.\",\n",
        "    \"future\": \"Show this scene one second in the future\",\n",
        "    \"past\": \"Show this scene one second in the past\",\n",
        "    \"funny\": \"Subtly alter this image by replacing one or two details with something unexpected and funny.\",\n",
        "    \"serious\": \"Subtly alter this image by replacing one or two details with something more serious, meaningful, or thought-provoking.\",\n",
        "    \"dramatic\": \"Subtly enhance the drama and intensity of this scene. Adjust lighting to be more cinematic, deepen shadows, or add atmospheric elements like mist or dramatic sky. Keep changes photorealistic and well-integrated.\",\n",
        "    \"peaceful\": \"Transform this scene to be more peaceful and serene. Soften harsh elements, add calming details like gentle lighting or natural elements. Keep changes subtle and photorealistic.\",\n",
        "    \"vintage\": \"Apply a subtle vintage aesthetic to this image. Add slight film grain, adjust colors to warmer or cooler vintage tones, and create a nostalgic atmosphere while maintaining photorealism.\",\n",
        "    \"futuristic\": \"Subtly modernize or add futuristic elements to this scene. Replace one or two objects with sleek, high-tech alternatives. Keep changes minimal, well-integrated, and photorealistic.\",\n",
        "    \"nature\": \"Subtly introduce natural elements into this scene. Add plants, natural lighting, or organic textures. Keep changes small and seamlessly integrated with photorealistic quality.\",\n",
        "    \"urban\": \"Subtly add urban elements to this scene. Introduce architectural details, city textures, or modern infrastructure. Keep changes minimal and photorealistic.\",\n",
        "    \"minimalist\": \"Simplify this scene with minimalist aesthetics. Remove or tone down one or two distracting elements, create cleaner compositions, and emphasize negative space. Keep it photorealistic.\",\n",
        "    \"crowded\": \"Subtly add more people or objects to make this scene feel more populated or busy. Keep additions natural, well-integrated, and photorealistic.\",\n",
        "    \"empty\": \"Subtly remove one or two people or objects to make this scene feel more spacious or isolated. Keep the result natural and photorealistic.\",\n",
        "}\n",
        "\n",
        "if task_or_prompt in prompts:\n",
        "  prompt = prompts[task_or_prompt]\n",
        "  output_filename = task_or_prompt + '.mp4'\n",
        "else:\n",
        "  prompt = task_or_prompt\n",
        "  output_filename = 'custom.mp4'\n",
        "print(prompt)\n",
        "\n",
        "total_frames = max(2, round(duration_secs * fps))\n",
        "digits = len(str(total_frames))\n",
        "\n",
        "!rm -rf /content/output\n",
        "!mkdir /content/output\n",
        "image = init_image\n",
        "image.save(f'/content/output/{\"0\".zfill(digits)}.jpg')\n",
        "\n",
        "gen = torch.Generator('cuda').manual_seed(seed)\n",
        "\n",
        "start_time = perf_counter()\n",
        "\n",
        "for i in range(1, total_frames):\n",
        "  image = pipe(image=image, prompt=prompt, negative_prompt=negative_prompt, true_cfg_scale=cfg, num_inference_steps=steps, generator=gen).images[0]\n",
        "  image.save(f'/content/output/{str(i).zfill(digits)}.jpg')\n",
        "\n",
        "dt = perf_counter() - start_time\n",
        "print(f'took: {dt:.0f} secs, {dt/duration_secs:.1f} sec/sec, {dt/(total_frames - 1):.1f} sec/frame')\n",
        "\n",
        "!ffmpeg -framerate $fps -i \"/content/output/%0{digits}d.jpg\" -pix_fmt yuv420p -movflags +faststart -y $output_filename -hide_banner -loglevel error\n",
        "Video(output_filename, embed=True, html_attributes='autoplay controls loop')\n"
      ],
      "metadata": {
        "id": "-FIxGneDLATY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KdAY3Boydi8S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}